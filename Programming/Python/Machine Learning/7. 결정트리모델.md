# 결정 트리 모델이란?

- 분류와 회귀 모두 가능한 지도 학습 모델이다. 
- Yes or No 짊문들로 이어가며 학습을 하는 모델이다.
- 특정 질문에 따라 데이터를 구분해나가는 학습이다. 
- 한번의 분기 때 마다 두 개로 구분한다. 
- 질문이나 정답의 네모 상자는 Node라고 한다.
- 맨 처음에 나오는 분류 기준을 Root Node라고 한다.
- 맨 마지막에 나오는 분류 기준을 Terminal 혹은 Leaf Node라고 한다. 

# 결정 트리 모델 프로세스(과정)
- 질문들을 기준으로 나눈다.
- 위에서 나뉜 범주에서 또 다시 질문들을 기준으로 나눈다. (다만, 짊문들을 기준으로 지나치게 나누면 오버피팅이 생길 수 있다. (이를 막기 위한 방법 : 가지치기)) 

- 가지치기 종류 : 사전 가지치기(pre-pruning), 사후 가지치기(post-pruning)

- 사전 가지치기 : 트리생성을 일찍 중단시킨다. (트리의 최대 깊이 혹은 Reaf Node의 최대 개수를 제한하거나 Node가 분할하기 위한 포인트의 최소한계를 지정한다.)
- 사후 가지치기 : 트리를 만든 후에 데이터 포인트가 적은 노드를 삭제하거나 병합시키는 방법이다.

- 특성 중요도 : 트리를 만드는 결정에 각 특성이 얼마나 중요한지를 보는 것
    - (해당 값은 0과 1 사이의 숫자이며 0은 각 특성에 대해 전혀 사용되지 않았음을 말하고 1은 완벽하게 타겟 클래스를 예측을 하였다는 것을 말한다.)
    - (특성 중요도의 전체 합은 1이다.)
    - 특성 중요도가 높을 경우 트리 구조에서 높은 위치에 위치하고 특성 중요도가 낮을 경우에는 트리 구조에서 낮은 위치에 위치하거나 아예 포함되지 않을 수도 있다. (특성 중요도가 낮다고 중요하지 않은 데이터는 아니다.)


# 결정 트리 장점
- 알고리즘이 매우 직관적이다.
- 룰이 매우 뚜렷하며, 규칙 노드와 Reaf Node를 알기 쉽고 규칙 파악도 용이하다. 
- 전처리 같은 작업들이 덜 필요하다.
- 교호효과 : 두 개 이상의 변수가 결합해서 y에 어떠한 영향을 끼치는지 자동적으로 알려주는 것. (중요변수(어떤 것이 더 영향을 많이 끼쳤는가)를 알기 쉽다.)

# 결정 트리 단점 
- 과적합 가능성이 높다.
- 모델의 유연성이 떨어지며 학습 데이터에 따라 생성되는 의사결정나무의 차이가 있다 (일방성 부족, 상대적으로 정확성이 떨어짐)